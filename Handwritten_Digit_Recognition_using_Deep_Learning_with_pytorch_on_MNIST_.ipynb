{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnTc6OSaBTwzeLxFG9J51C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UMAIR-777/Certifcations/blob/main/Handwritten_Digit_Recognition_using_Deep_Learning_with_pytorch_on_MNIST_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ":Project Overview:\n",
        "Implement a deep learning model to recognize handwritten digits from the MNIST dataset. The goal is to train a model that can accurately classify images of digits into their respective categories (0 through 9)."
      ],
      "metadata": {
        "id": "pbkL9woi8cQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project Steps:\n",
        "\n",
        "Data Preparation:\n",
        "\n",
        "Load and preprocess the MNIST dataset.\n",
        "Normalize pixel values.\n",
        "Split the dataset into training and testing sets.\n",
        "Model Architecture:\n",
        "\n",
        "Choose a deep learning architecture, such as a Convolutional Neural Network (CNN).\n",
        "Define the model architecture using a deep learning framework (e.g., TensorFlow or PyTorch).\n",
        "Model Training:\n",
        "\n",
        "Train the model on the training set.\n",
        "Experiment with hyperparameters like learning rate, batch size, and the number of layers.\n",
        "Model Evaluation:\n",
        "\n",
        "Evaluate the trained model on the testing set.\n",
        "Measure accuracy and other relevant metrics.\n",
        "Visualization:\n",
        "\n",
        "Visualize the model's performance using confusion matrices, precision-recall curves, or other appropriate visualizations.\n",
        "Model Deployment (Optional):\n",
        "\n",
        "Deploy the trained model to recognize handwritten digits in real-world scenarios.\n",
        "Tools and Technologies:\n",
        "\n",
        "Deep learning framework (e.g., TensorFlow, PyTorch)\n",
        "Python programming language"
      ],
      "metadata": {
        "id": "-EEsfcLl8jvV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLvPAt4Dx5yT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "torch.manual_seed(0)\n",
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.pylab as plt\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "# In[2] Plot function\n",
        "\n",
        "# Define the function for plotting the channels\n",
        "\n",
        "\n",
        "def show_data(data_sample):\n",
        "    plt.imshow(data_sample[0].numpy().reshape(IMAGE_SIZE, IMAGE_SIZE), cmap='gray')\n",
        "    plt.title('y = ' + str(data_sample[1]))\n",
        "\n",
        "\n",
        "# In[3] Create Data\n",
        "\n",
        "\n",
        "IMAGE_SIZE = 16\n",
        "\n",
        "# Create a transform to resize image and convert to tensor\n",
        "composed = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), transforms.ToTensor()])\n",
        "\n",
        "# Create Dataset from MNIST and apply composed transformation\n",
        "dataset_train = dsets.FashionMNIST(root='.fashion/data', train=True, download=True, transform=composed)\n",
        "dataset_val = dsets.FashionMNIST(root='.fashion/data', train=False, download=True, transform=composed)\n",
        "\n",
        "for n, data_sample in enumerate(dataset_val):\n",
        "\n",
        "    show_data(data_sample)\n",
        "    plt.show()\n",
        "    if n == 2:\n",
        "        break\n",
        "\n",
        "\"\"\" Question: Take a screen shot of the first three images of the validation dataset from the code provided.\n",
        "              The function show_data\n",
        "\"\"\"\n",
        "\n",
        "show_data(dataset_val[0])\n",
        "show_data(dataset_val[1])\n",
        "show_data(dataset_val[2])\n",
        "\n",
        "# In[4] Create CNN Class\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "\n",
        "    # Constructor\n",
        "    def __init__(self, out_1=16, out_2=32):\n",
        "        super().__init__()\n",
        "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=out_1, kernel_size=5, padding=2)\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.ELU = nn.ELU()\n",
        "        self.cnn2 = nn.Conv2d(in_channels=out_1, out_channels=out_2, kernel_size=5, padding=2)\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.fc1 = nn.Linear(out_2*4*4, 10)\n",
        "\n",
        "    # Prediction\n",
        "    def forward(self, x):\n",
        "        x = self.cnn1(x)\n",
        "        x = self.ELU(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.cnn2(x)\n",
        "        x = self.ELU(x)\n",
        "        x = self.maxpool2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "    # Outputs in each step\n",
        "    def activations(self, x):\n",
        "        # This part is for visualization purposes\n",
        "        z1 = self.cnn1(x)\n",
        "        a1 = self.ELU(z1)\n",
        "        out = self.maxpool1(a1)\n",
        "        z2 = self.cnn2(out)\n",
        "        a2 = self.ELU(z2)\n",
        "        out1 = self.maxpool2(a2)\n",
        "        out2 = out1.view(out1.size(0), -1)\n",
        "        return z1, a1, out, z2, a2, out1, out2\n",
        "\n",
        "\n",
        "# In[5] Batch Normalization CNN class\n",
        "\n",
        "\n",
        "class CNN_BatchNorm(nn.Module):\n",
        "    # Constructor\n",
        "    def __init__(self, out_1=16, out_2=32):\n",
        "        super().__init__()\n",
        "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=out_1, kernel_size=5, padding=2)\n",
        "        self.conv1_bn = nn.BatchNorm2d(out_1)  # To normalize conv2D, we need BatchNorm2D\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.ELU = nn.ELU()\n",
        "        self.cnn2 = nn.Conv2d(in_channels=out_1, out_channels=out_2, kernel_size=5, padding=2)\n",
        "        self.conv2_bn = nn.BatchNorm2d(out_2)\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.fc1 = nn.Linear(out_2*4*4, 10)\n",
        "        self.bn_fc1 = nn.BatchNorm1d(10)  # To normalize linear layer, BatchNorm1D must be used\n",
        "\n",
        "    # Prediction\n",
        "    def forward(self, x):\n",
        "        x = self.cnn1(x)\n",
        "        x = self.conv1_bn(x)\n",
        "        x = self.ELU(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.cnn2(x)\n",
        "        x = self.conv2_bn(x)\n",
        "        x = self.ELU(x)\n",
        "        x = self.maxpool2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn_fc1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# In[6] Initialize, create loss function, optimizer and data loaders\n",
        "\n",
        "# Loss function criterion\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# train and val loader\n",
        "train_loader = DataLoader(dataset=dataset_train, batch_size=100)\n",
        "validation_loader = DataLoader(dataset=dataset_val, batch_size=100)\n",
        "\n",
        "# Create model_BatchNorm object from CNN_BatchNorm class\n",
        "model = CNN_BatchNorm(16, 32)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "\n",
        "# In[6] Train loop and training\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "cost_list = []\n",
        "accuracy_list = []\n",
        "N_test = len(dataset_val)\n",
        "n_epochs = 5\n",
        "for epoch in range(n_epochs):\n",
        "    cost = 0\n",
        "    model.train()\n",
        "    for x, y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        z = model(x)\n",
        "        loss = criterion(z, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        cost += loss.item()\n",
        "    correct = 0\n",
        "    # Perform a prediction on the validation data\n",
        "    model.eval()\n",
        "    for x_test, y_test in validation_loader:\n",
        "        z = model(x_test)\n",
        "        _, yhat = torch.max(z.data, 1)\n",
        "        correct += (yhat == y_test).sum().item()\n",
        "    accuracy = correct / N_test\n",
        "    accuracy_list.append(accuracy)\n",
        "    cost_list.append(cost)\n",
        "\n",
        "# In[7] Analyze Results and Compare\n",
        "\n",
        "# Plot the loss and accuracy\n",
        "fig, ax1 = plt.subplots()\n",
        "color = 'tab:red'\n",
        "ax1.plot(cost_list, color=color)\n",
        "ax1.set_xlabel('epoch', color=color)\n",
        "ax1.set_ylabel('Cost', color=color)\n",
        "ax1.tick_params(axis='y', color=color)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('accuracy', color=color)\n",
        "ax2.set_xlabel('epoch', color=color)\n",
        "ax2.plot(accuracy_list, color=color)\n",
        "ax2.tick_params(axis='y', color=color)\n",
        "fig.tight_layout()"
      ]
    }
  ]
}